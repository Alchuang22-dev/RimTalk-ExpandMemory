# ?? Token优化 v3.3.2 - 隐藏式命令处理

## ?? **问题：Token浪费严重**

### **之前的问题：**

```
AI输出：
"让我想想... [DB:我和Alice的对话] ..."

替换后显示给用户：
"让我想想... 
[数据库查询结果: 找到 3 条相关记录]
1. [今天] [对话] Alice跟我说她想学烹饪
2. [昨天] [对话] Alice问我食材在哪
3. [前天] [对话] 我教Alice怎么烹饪
..."

问题：
? 命令本身占用token（"[DB:xxx]"）
? 完整查询结果显示给用户，占用大量token
? 下次对话时，查询结果会被包含在对话历史中，再次消耗token
? 长期下来，token消耗累积严重
```

**Token消耗分析：**
```
[DB:我和Alice的对话] → 10 tokens
查询结果（3条记忆） → 150 tokens
下次对话历史包含 → 再次150 tokens

单次对话总消耗：310 tokens
10次对话累积：3100 tokens
```

---

## ? **解决方案：隐藏式处理**

### **优化后的流程：**

```
AI输出：
"让我想想... [DB:我和Alice的对话] ..."

↓ 后台处理

用户看到：
"让我想想... ?? ..."  ← 仅显示思考图标

内部上下文（仅AI可见）：
[查询：我和Alice的对话]
1. [今天] [对话] Alice跟我说她想学烹饪
2. [昨天] [对话] Alice问我食材在哪
3. [前天] [对话] 我教Alice怎么烹饪

存储位置：ABM（Active Buffer Memory）
下次对话自动注入，不占用对话历史token
```

**Token节省：**
```
用户可见："??" → 2 tokens
内部上下文：存入ABM → 0 tokens（不进对话历史）
下次对话：从ABM自动注入 → 150 tokens（仅一次）

单次对话消耗：2 tokens
节省：308 tokens（99.4%）
10次对话累积节省：3080 tokens
```

---

## ?? **技术实现**

### **1. 命令处理优化**

**之前（AIDatabaseCommands.cs）：**
```csharp
// 直接替换命令为查询结果
result = result.Replace(
    "[DB:xxx]", 
    "[数据库查询结果: ...完整内容...]"
);
```

**现在：**
```csharp
public class ProcessedResponse
{
    public string UserVisibleText;  // 用户看到的（仅图标）
    public string InternalContext;  // AI内部上下文（完整结果）
}

// 隐藏命令，结果存入内部上下文
UserVisibleText: "??"
InternalContext: "[查询结果] 完整内容..."
```

### **2. 内部上下文存储**

**AIResponsePostProcessor.cs：**
```csharp
// 存储为Internal类型记忆（ABM层级）
var contextMemory = new MemoryEntry(
    "[查询上下文] ...",
    MemoryType.Internal,  // ← 新增类型
    MemoryLayer.Active    // ← ABM自动管理
);

// ABM满了自动清理旧的Internal记忆
if (memoryComp.ActiveMemories.Count >= 6)
{
    RemoveOldestInternal();
}
```

### **3. 下次对话自动注入**

**SmartInjectionManager.cs：**
```csharp
// ABM内容会被自动注入到下次对话
// Internal类型记忆会被格式化为AI可读的上下文
// 用户不可见，但AI可以访问
```

---

## ?? **Token节省对比**

### **单次对话：**

| 场景 | v3.3.1 | v3.3.2 | 节省 |
|------|--------|--------|------|
| 用户输入 | 50 tokens | 50 tokens | 0 |
| AI输出（含命令） | 100 tokens | 100 tokens | 0 |
| 命令替换结果 | 150 tokens | 2 tokens | **148 tokens** |
| **总计** | **300 tokens** | **152 tokens** | **49%** ?? |

### **连续对话（10次）：**

| 场景 | v3.3.1 | v3.3.2 | 节省 |
|------|--------|--------|------|
| 首次查询 | 300 tokens | 152 tokens | 148 tokens |
| 第2次（历史包含） | 450 tokens | 152 tokens | 298 tokens |
| 第3次 | 600 tokens | 152 tokens | 448 tokens |
| ... | ... | ... | ... |
| 第10次 | 1500 tokens | 152 tokens | 1348 tokens |
| **累积总计** | **4500 tokens** | **1520 tokens** | **66%** ?? |

---

## ?? **用户体验**

### **用户视角：**

**之前：**
```
Alice: "你还记得我们之前聊烹饪的事吗？"

Bob: "让我想想... 
[数据库查询结果: 找到 3 条相关记录]
1. [今天] [对话] Alice跟我说她想学烹饪
2. [昨天] [对话] Alice问我食材在哪
3. [前天] [对话] 我教Alice怎么烹饪

当然记得！你说你想学烹饪..."
```
? 暴露了系统内部机制
? 破坏沉浸感
? 占用大量token

**现在：**
```
Alice: "你还记得我们之前聊烹饪的事吗？"

Bob: "让我想想... ?? 当然记得！你说你想学烹饪..."
```
? 自然流畅
? 保持沉浸感
? token节省66%

---

## ?? **AI视角**

### **内部处理流程：**

```
1. AI生成响应：
   "让我想想... [DB:我和Alice的对话] ..."

2. 后台命令处理：
   → 查询数据库
   → 获取结果：3条记忆
   → 隐藏命令：替换为 "??"
   → 存储上下文到ABM

3. 用户看到：
   "让我想想... ?? ..."

4. 下次对话时：
   → AI自动从ABM获取上下文
   → 不占用对话历史token
   → 保持上下文连贯性
```

---

## ?? **配置选项**

### **默认配置（推荐）：**
```
隐藏式命令处理：? 启用（自动）
内部上下文存储：? ABM自动管理
显示思考图标：? 显示 "??"
```

### **可选配置：**

#### **1. 完全隐藏图标**
修改 `AIDatabaseCommands.cs`:
```csharp
string userVisible = $""; // 完全隐藏，不显示图标
```

#### **2. 自定义图标**
```csharp
string userVisible = $"??"; // 或其他表情
```

#### **3. 简短提示**
```csharp
string userVisible = $"(思考中)";
```

---

## ?? **注意事项**

### **1. ABM容量限制**
- ABM固定容量：6条
- Internal记忆会自动清理旧的
- 不会影响其他类型记忆

### **2. 上下文有效期**
- 存储在ABM中，会随ABM自然过期
- 约10-20分钟游戏时间
- 足够支持连续对话

### **3. 兼容性**
- 向后兼容：旧存档不受影响
- 可随时禁用：关闭RAG检索即可
- 不影响手动查看记忆

---

## ? **验证优化效果**

### **测试步骤：**

1. **启动对话测试**
```
Alice: "你还记得我们的对话吗？"
```

2. **观察AI响应**
```
预期：看到 "??" 而不是完整查询结果
```

3. **查看DevMode日志**
```
[AI Database Commands] Processed 1 commands
[AI Response Processor] Stored context for next conversation
```

4. **继续对话**
```
Alice: "那你记得哪些细节？"

预期：AI能正确引用上下文，但对话历史中不包含查询结果
```

---

## ?? **成本估算**

### **API成本节省：**

**场景：DeepSeek API（?0.001/1K tokens）**

| 对话次数 | v3.3.1成本 | v3.3.2成本 | 节省 |
|----------|------------|------------|------|
| 10次 | ?0.0045 | ?0.0015 | **66%** |
| 100次 | ?0.045 | ?0.015 | **66%** |
| 1000次 | ?0.45 | ?0.15 | **?0.30** |

**月成本对比（假设每天100次对话）：**
```
v3.3.1: ?1.35/月
v3.3.2: ?0.45/月
节省: ?0.90/月（66%）
```

---

## ?? **下一步优化**

### **v3.3.3 计划：**

1. **智能上下文压缩**
   - 对长查询结果进行摘要
   - 进一步减少ABM占用

2. **上下文优先级**
   - 重要上下文保留更久
   - 自动清理低优先级上下文

3. **跨对话上下文**
   - 支持长期上下文（ELS层级）
   - 更好的上下文连贯性

---

**v3.3.2 Token优化完成！节省66% token消耗！** ??
